# 并发编程的底层实现及原理:
	CPU术语定义：
		内存屏障（Memory barriers）:是一组处理器指令，用于实现对内存操作的顺序限制。
		缓冲行(Cache line): 是缓存中可以分配的最小存储单元。处理器填写缓存线时会加载整个缓存线，需要使用多个主内存读周期。
		原子操作（Atomic operations）:不可中断的一个或者多个操作
		缓存行填充(Cache line fill): 当处理器识别到从内存中读取操作数是可以缓存的，处理器读取整个缓存行到适当的缓存；（L1,L2,L3）
		缓存命中:

		写缺失：一个有效的缓存行被写入到不存在的内存区域



# 在并发编程中，需要处理两个关键的问题:
	1.线程间如何通信；
			通信:指线程间如何交换信息。
				a)：内存共享； 在共享的内存模型里，线程共享程序里的公共状态， 隐试的通信
				b):消息传递； 在消息传递的模型里，线程通过发送消息 显示进行通信
	2.线程间如何同步;
			同步是指 控制不同线程间 操作发生相对顺序的机制。
			在共享内存模型里，同步是显示指定的。即在程序中要显示指定同步块


    Java的并发采用共享的内存模型；Java线程之间的通信总是隐式进行


###  JAVA内存模型(JMM模型)：
    JMM决定一个线程对共享变量的写入何时对另外一个线程可见。 从抽象角度看，JMM定义线程与主内存之间的抽象关系；
    线程间的共享变量都存储在主内存中(main memory),每个线程都有一个私有的本地内存。  


    Java中每个对象都可以做为锁，具体表现：
        普通的同步方法，锁是当前实例对象
        静态的同步方法，锁是当前类的Class对象
        同步方法块，锁是Synchronized后面括号中配置的对象
    
    当一个线程试图进入一个同步代码块，他必须先得到锁， 如果出现异常或者运行结束必须释放锁。

### 那么锁存在哪里？ 存储的是什么?
      对象头中锁状态变化:
        无锁状态 (new一个对象)------>偏向锁（有线程持有改对象的monitor,将持有锁的线程ID写入到对象头）----多个线程尝试竞争这个锁---升级为---> 轻量级锁(又称无锁,自旋锁,自适应锁. 使用CAS 循环竞争锁)-----自选次数太多JVM将锁升级---> 重量级锁（前面几种都是用户态操作， 重量级锁是在内核态中申请锁定，线程进入等待池，不在消化CPU。 多个线程CAS自旋很消耗CPU）。 


### Object o = new Object() 在内存中占多少空间
	分析:
		1. 类加载到Object后将 在方法区创建Object. Klass 对象。 在堆中分配一块地址存 "o" 对象。
		2. 虚拟机栈-栈帧中存了o引用地址--->指向堆
		3. 在堆中创建o 对象时，除了对象本身的数据 ，还有对象头，
		4. 对象在堆中的内存布局:对象头 (maskword),对象实例数据,对齐填充(Padding)（虚拟机为了性能，要求对象内存大小是8的倍数，不够就需要填充）。
		5. Object 没有其它数据 ，因此只有对象头。
		6. 对象头信息含: Markword（8字节=64bit 64位机）,类型引用指针（4字节 默认被压缩所以64位下4个字节，关闭就8字节），数组长度(4字节)，对齐填充(padding)

		对象头
	------长度----|----------内容-------------|---------说明-----------------------
	32bit/64bit.  |.   MarkWord              |   存储对象的identity_hashcode,锁信息，分代年龄    不会被压缩
	32bit/64bit   |    Class Metadata Address|   类型指针地址
	32bit/32bit.  |    Array length          |   数组长度 

	我们现在使用的64位 JVM会默认使用选项 -XX:+UseCompressedOops  -XX:+UseCompressedClassPointers开启指针压缩，将指针压缩至32位

	UseCompressedOops：普通对象指针压缩，oops: ordinary object pointer
	UseCompressedClassPointers：类指针压缩
	开启UseCompressedOops，默认会开启UseCompressedClassPointers，会压缩class pointer 这部分的大小;
	UseCompressedClassPointers的开启是依赖于UseCompressedOops的开启,关闭UseCompressedOops 默认关闭UseCompressedClassPointers
	如果开启类指针压缩，+UseCompressedClassPointers，并关闭普通对象指针压缩，-UseCompressedOops，此时会报错，
	Java HotSpot(TM) 64-Bit Server VM warning: UseCompressedClassPointers requires UseCompressedOops


## 偏向锁:
	偏向锁出现的背景： 大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获取，为了让线程获取锁的代价更低而引入偏向锁。
	偏向锁获取:
		当一个线程访问同步块并获得锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程再进入同步块时不需要进行CAS操作来加锁， 只需要简单地测试一下对象头的markword里是否存储着指向当前线程的偏向锁，测试成功得到锁；
		测试失败，需要进一步测试markword中偏向锁的标示是否设置为1（表示当前是偏向锁）：
			如果没有设置，则使用CAS竞争锁；-----可能情况. 1.对象是无锁状态，2. 升级为轻量级锁. 需要使用CAS 自旋 竞争锁。 ----理解可能还是有点问题
	  		如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。   ---- 如果设置了，代表改锁是偏向锁， 使用CAS原子操作竞争锁。


	偏向锁取消:
		偏向锁使用一种等到竞争者出现才释放锁的机制，所以当有其它线程尝试竞争锁的时候 持有偏向锁的线程才会释放锁。



## 轻量级锁:
	获取锁流程:
		线程在执行同步块之前，JVM会在当前线程的栈帧中创建用于存储锁记录的空间,并将对象头中的markword复制到锁记录中。 
		然后线程尝试使用CAS将对象头中的markword替换为指向锁记录的指针。
		操作成功，获取锁；
		操作失败，说明有其它线程得到锁，使用CAS继续尝试获得锁。

	所释放流程:	
		1.使用CAS操作将 栈帧中的markword替换回对象头。 如果成功，表示没有竞争发生；
		2.否则，失败，因锁激烈竞争膨胀成重量级锁。
		3.释放锁，换醒等待池的中线程
		一旦锁升级为重量级锁后，其它线程都将堵塞，进入到等待队列中。 等待持有锁的线程释放锁，在重新竞争锁（非公平竞争）
	

## 原子操作(CAS):
	CAS : 全称 Compare And Swap.  CAS操作时需要传2个参数， 一个旧值，一个新值。 先用旧值与内存中的值比较，如果相同就将新值替换到内存中。
	CAS操作在底层原理也是同步 。他在底层的指令Lock CMPXCHG

	内存顺序冲突:多个CPU 同时修改同一个缓存行中的不同共享变量而引起其中一个CPU操作无效。 当出现这个内存顺序冲突时，CPU必须清空流水线。

	CPU流水线：
		在CPU中，有5-6个不同的功能电路单元组成一条指令处理流水线。然后将一条X86指令分成5-6步后再由这些电路单元分别执行。
		这样就能实现在一个CPU时钟周期完成一条指令，因此提高CPU的运算速度



    处理器如何实现原子操作：
        1.在32位IA-32处理器 使用对缓存加锁或者总线加锁的方式实现多处理器之间的原子操作。
        2.在最新的处理器，能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的。但是复杂的内存操作 处理器是不能自动保证其原子性的。比如跨总线宽度、跨多个缓存行，跨页表的访问。
        处理器提供，总线锁定和缓存锁两个机制保证复杂内存操作的原子性。
    
    概念:
        总线锁定：
            总线锁定的开销比较大，总线锁定期间，其它处理器不能操作其它内存地址。
        缓存锁定:
            缓存锁定，保证同一时刻对某个内存地址操作是原子性即可。目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。
            是指缓存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声明Lock#信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保障操作的原子性。
            简单理解。一个共享变量，从主内中被缓存到各处理器的缓存行中，这个共享变量加了volital或者synchnorized lock 。对这个变量进行写操作时，根据缓存一致性协议，其它处理器不能同时回写这个变量，当CPU1 回写完后，其它CPU中这个存这个变量的缓存行将失效。
        缓存一致性协议:
            缓存一致性机制会阻止两个以上处理器缓存的内存区域数据，当其它处理回写已被锁定的缓存行的数据时，会使缓存行无效。
            如.CPU 修改缓存行中i变量时使用了缓存锁定，那么CPU1，CPU2，中缓存i的缓存行将失效。
    
    会进行缓存锁定或者内存锁定的指令:
        1.位测试或者修改指令: BTS,BTR,BTC...
        2.交换指令:XADD,CMPXCHG...
        3.操作数和逻辑指令:ADD,OR...
    
    
    备注:
        某些情况是不支持缓存锁定，只能使用总线锁定
        比如: 
            1.当前操作的数据不能被缓存在处理器内部
            2.当前操作的数据跨多个缓存行
            3.处理器不支持缓存锁定。Intel 486 、 Pentium处理器
    
    
    使用CAS实现的原子操作遇到的3大问题:
        1.ABA问题
            CAS操作时会传入旧值，新值。 旧值与内存中的值比较，两者相等就可以更新。  这里内存的值可能中间发生过变化后，又变成了变化前的值。  造成比较的时候两个值一样，但是已经不是最开的那个值了。
            解决这个问题的方法是对内存的值加一个版本。比较值的同时也比较版本是否一致。  JDK atomic 包引入的AtomicStampedReference 类需要传入(expectedReference,newReference,expectedStamp,newStamp)

        2.循环时间开销大
            自旋CAS如果长时间不成功，会给CPU带来非常大的开销。
    
        3.只能保证一个变量的原子性
            当对一个共享变量进行CAS操作时可以保证原子性，但是多个共享变量是不能保障。JDK 提供了AtomicReference 类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里进行CAS操作





## volatile要点
    volatile 只保证变量的线程可见性，不保证变量的原子性（只对赋值起作用），另外一个作用是防止重排序。
    
    volatile 典型的使用场景，作为boolean，采用while来做信号通知
    
    单例模式，懒汉模式 双重检查 instance需要被 volatile 修饰。
    不采用volatile的dcl容易出错（DCL即Double Check Locking模式，就是双加锁检查模式。）
    
    JIT优化的时候有 指令重排序，如果不加 volatile可能造成instance 直接返回 半实例化状态的实例 （数据只是给初始化0值，并没有完成初始化）。  
    
    没有volatile 指令在7，4间会有可能进行重拍下，造成其它线程获取到的 instance是半实例化对象（没有真正的赋值）。
    class T{
        private int m=9;
    }
    
    0 new #2 <T>
    4 invokespecial #3 <T.<init>>        4 与 7 指令交换 后，线程T1 instance 已经不等于 null    T2进来后发现 instance!=null后就直接返回了。得到的m值就会等于0     
    7 astore_1


## 锁优化：
	高效并发是JDK1.5到JDK1.6的一个重要改进。Hotspot团队划分了大量精力去实现各种锁优化。

	主要有： 适应性自旋锁，锁消除，锁粗化，偏向锁，轻量级锁。 锁细粒度

	这些优化都是为了在线程间更高效的共享数据，以解决竞争问题。



	自旋锁/自适应锁：
		背景:	
			在老版本JDK中，Sychnorized 是一个非常重量级的锁，它需要在操作系统内核中去申请锁，让等待的线程进入等待队列中（挂起），申请到锁的线程在重新启用（恢复）。线程的挂起和恢复操作都需要转入内核中完成，给并发性能带来很大的压力。

			虚拟机开发团队注意到，在大多数应用上，共享数据的锁定状态持续时间很短，为了这段时间去挂起和恢复线程并不值得。因此自旋锁出来。

		自旋锁：一个线程在持有锁后，另外并行的线程发现锁被其它线程持有，就循环的询问锁是否已经释放，如果释放自己就占用锁。  以前JDK版本自旋次数是10次，可以通过-XX:PreBoockSpin来更改。

		适应性自旋锁：
			后来JDK1.6后引入了适应性自旋，这意味着自旋次数不固定。 它是由前一次 在一同个锁上的 自旋时间及锁的拥有者状态 来觉得。  如果在同一个锁对象上，自旋等待很快就获得了锁，会认为自己也会自旋等待很短时间获得锁。

	锁消除:
		 锁消除是指 虚拟机即时编译器 在运行时 对要求同步的一些代码块做检测，对检测到 不可能存在 共享数据竞争的 锁进行消除。	

		 比如在方法中 我们定义了StringBuffer .append("xxx").append("xxx") ;  append是同步方法，但是这个 StringBuffer只是在这个方法内被使用到，可以进行锁消除。

		 锁消除的判断依据源于 逃逸分析的数据支持（JVM 11章讲解到逃逸分析技术）， 在堆中所有数据都不会逃逸出去从而被其它线程访问到，那就可以把他们当作栈上的数据对待， 认为他们是线程私有的，
		 同步加锁也就没有必要了。

	锁粗化:
		原则上，我们在写代码的时候，尽量将同步限制在最小范围--只在共享数据的实际范围内同步。刚刚上面说的自旋锁 最好使用在 执行时间短的模块中。

		大部分情况这个原则是有效的， 但是 如果一系列的 连续操作 都对 同一个对象 反复 加锁和解锁， 甚至 这个同步在 循环中。 即使没有多线程竞争，加锁，解锁也会导致不要的性能损耗。

		为了因对这种情况 将会把枷锁同步的范围扩大到整个操作序列的外部。只加一次锁就好了。

	偏向锁/轻量级锁 的锁过程在上面已经阐述过了，具体参考JVM（13章 锁优化）




## Synchnorized:
	1.锁的对象
		案例1:
		public class T{
			public synchnorized void method(){} 锁住的是 t 对象，没创建一个t锁的对象就不一样了
		}

		锁的标记记录在 对象都的mark word中。（对象头）

		public class T{
			final Object o = new Object();
			public void method(){
				synchnorized(o) {. //锁的是o的对象

				}
				synchnorized(this) {   //同案例1，锁的是T这个实例对象 （对象在堆区）

				}

			}

			public static synchnorized void method(){} //锁的是 T.class对象（Class对象在方法区）
		}

		synchnorzied（o） ： o禁止是 String，Integer,Long这样的基础包装类。
		比如:String a="123", b="123" 在常量池中他们的地址是同一个，锁住的就是同一个，Integer 。。。等因为在内部实现中也有Cace所以会是同一个对象。

		

	2.锁升级过程


## AtomicXXX
	
	内部定义了一个用volatile 修饰的变量，对外抛出 递增，递减的方法 传入旧值和新值。 内部实现使用的Unsafe类的CompareAndSwapXX本地方法，这个是一种自旋的方式原子更新值。需要传入（操作的对象，对象中代修改变量地址，旧值，新增）
	X86 指令集（CPU原语）是使用了cmpxchg指令完成CAS功能


## ReentrantLock VS Synchnorized:
	可重入锁，
	ReentrantLock API层面的互斥锁，用法上需要 lock()与unlock配合，unlock()一般套在finllay方法块中

	内部实现，对一个共享变量进行CAS操作。state >0得到锁，小于0没有锁。
	与Synchnorize 相比，它提供更多的可控性：
	1.tryLock 等待可中断
	2.可实现公平锁， 按照申请锁的时间顺序来一次获得锁。 而非公平锁不能保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。 Synchnorized是非公平的。
	3.锁可以绑定多个条件Condition.

## CountDownLantch:


## Semaphore: 共享锁

## CyclicBarrier:

## Phaser （JDK1.7新出来的功能）:
	分阶段完成任务。
	phaser.bulkRegister(7);//指定线程数
	phaser.arriveAndAwitAdvance();//继续下一个阶段
	phaser.arriveAndDeregister();//离开

## ReentrantReadWriteLock:读写锁
	1.共享锁（读）和排它锁（写）
	使用锁分离的机制提升性能。
	比如线程A1,A2,A3是写操作，B1,B2,B3是读操作。 在不使用读写分离的时候，他们是串行的。 但是对于B线程，它对数据没有破坏性，是可以读的。前面说的方式肯定是无效的等待。读写锁分离就可解决这个问题。
	读写锁分离机制：
		允许 多个线程同时读， 但是对于读写，写写操作还是必须要相互等待。
	特性: 可重入，可公平，锁降级
		可重入：读线程获得读锁后，任何线程都能够再次得到读锁， 而写线程在获得写锁后，该线程可以继续获得写锁和读锁。
		锁降级: 遵循 获取写锁、获取读锁在释放读锁的顺序，写锁能降级为读锁

	如果在系统中读的操作次数远大于写的操作次数，对系统的性能提升是很大的。，	

	当获取写锁后，其它线程对于获取读锁和写锁均被阻塞，而只有写锁释放后其它读写锁操作才能继续。


	2.代码实现分析:
		ReentrantReadWriteLock实现，主要包含：读写状态设计，写锁的获取与释放，读锁的获取与释放，及锁降级

		读写锁状态设计：
			读写锁依赖AQS同比器，而锁状态就是AQS的同步状态。（AQS中state表示锁被一个线程重复得到次数）而
			读写锁需要将多个线程的读锁持有次数和一个线程的写锁持有次数同时维护在这个状态中。即 state状态，同时表达了读锁，写锁状态。

			设计思想：“按位切割使用” 这个变量 。  高16位代表读锁，低16位代表写锁

			假如当前state = S ;
			获取写锁状态：S & 0x0000FFFF (将高16位全部抹去)
			获取读锁状态: S >>> 16 (无符号右移动16位，地位补0)

			写锁+1: S+1
			读状态+1 : S+(1<<16) 即 S + 0x00010000 

		写锁的获取与释放:



## AbstractQueuedSynchronizer:


## LockSupport:


## 线程池:


## Executors:


## ForkJoin:



## FeatureTask:


## JMM 内存模型



## JMM 内存屏障






















